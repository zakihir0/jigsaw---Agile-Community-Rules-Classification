{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U unsloth==2025.6.12\n!pip install -U torchvision","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nimport os\nfrom datasets import load_dataset, Dataset\nfrom peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, LlamaForSequenceClassification\nfrom trl import SFTConfig, SFTTrainer\nimport pandas as pd\nimport numpy as np\n\nmax_seq_length = 2048 \ndtype = None          \nload_in_4bit = True   \n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 32, \n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0,    \n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\",\n    random_state = 3407,\n    use_rslora = False,  \n    loftq_config = None, \n)\n\nseed = 52\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprompt = '''You are given a comment on reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.'''\ntrain_df = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/train.csv')\ntest_df = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\n\nfrom datasets import load_dataset, Dataset\nfrom datasets import load_dataset\nfrom unsloth.chat_templates import get_chat_template\nfrom unsloth.chat_templates import standardize_sharegpt\n\n# tokenizer = get_chat_template(\n#     tokenizer,\n#     chat_template = \"qwen-2.5\",\n# )\nuser_prompt = \"\"\"\nSubreddit: r/{subreddit}\nRule: {rule}\nExamples:\n1) {positive_example_1}\nViolation: Yes\n\n2) {negative_example_1}\nViolation: No\n\n3) {negative_example_2}\nViolation: No\n\n4) {positive_example_2}\nViolation: Yes\nComment:\n{body}\nViolation: \"\"\"\n\nclasses = ['No', 'Yes']\n\ncolumns = ['subreddit', 'rule', 'positive_example_1', 'positive_example_2', 'negative_example_1', 'negative_example_2', 'body', 'rule_violation']\ndataset = [\n    [{\"role\": \"system\", \"content\": prompt},\n    {\"role\": \"user\", \"content\": user_prompt.format(subreddit=subreddit,\n                                                   rule=rule, \n                                                   positive_example_1=positive_example_1,\n                                                   positive_example_2=positive_example_2,\n                                                   negative_example_1=negative_example_1,\n                                                   negative_example_2=negative_example_2,\n                                                   body=body)},\n    {\"role\": \"assistant\", \"content\": classes[target]}]\n    for subreddit, rule, positive_example_1, positive_example_2, negative_example_1, negative_example_2, body, target  in train_df[columns].values]\n\ndef formatting(dataset):\n    texts = []\n    for i in range(len(dataset)):\n        texts.append(tokenizer.apply_chat_template(dataset[i], tokenize=False, add_generation_prompt=False))\n    return Dataset.from_dict({'text': texts})\n\ndataset = formatting(dataset)\n\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n    dataset_num_proc = 4,\n    packing = False, \n    args = TrainingArguments(\n        per_device_train_batch_size = 1,\n        gradient_accumulation_steps = 4, \n        warmup_steps = 5,\n        # max_steps = 5,\n        num_train_epochs = 1,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 10,\n        optim = \"paged_adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\",\n    ),\n)\n\nfrom unsloth.chat_templates import train_on_responses_only\n\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<|start_header_id|>user<|end_header_id|>\",\n    response_part = \"<|start_header_id|>assistant<|end_header_id|>\",\n)\n\ntrainer_stats = trainer.train()\n\nimport shutil\n\nfor path in os.listdir('/kaggle/working'):\n    try:\n        shutil.rmtree('/kaggle/working/' + path)\n    except:\n        pass\n\nmodel.save_pretrained_merged(\"llama-8b-instruct-jigsaw\", tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T06:34:51.68448Z","iopub.execute_input":"2025-07-26T06:34:51.684809Z","iopub.status.idle":"2025-07-26T06:35:54.433953Z","shell.execute_reply.started":"2025-07-26T06:34:51.684787Z","shell.execute_reply":"2025-07-26T06:35:54.433127Z"}},"outputs":[],"execution_count":null}]}